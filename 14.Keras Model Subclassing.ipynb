{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/umair/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/umair/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 90 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.4816 - categorical_accuracy: 0.2667 - val_loss: 1.5729 - val_categorical_accuracy: 0.2333\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 558us/step - loss: 1.3912 - categorical_accuracy: 0.3000 - val_loss: 1.4726 - val_categorical_accuracy: 0.2333\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 660us/step - loss: 1.3181 - categorical_accuracy: 0.3111 - val_loss: 1.3903 - val_categorical_accuracy: 0.2667\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 612us/step - loss: 1.2515 - categorical_accuracy: 0.3444 - val_loss: 1.3083 - val_categorical_accuracy: 0.2667\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 615us/step - loss: 1.1894 - categorical_accuracy: 0.3556 - val_loss: 1.2381 - val_categorical_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 585us/step - loss: 1.1314 - categorical_accuracy: 0.3778 - val_loss: 1.1719 - val_categorical_accuracy: 0.3000\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 646us/step - loss: 1.0769 - categorical_accuracy: 0.4000 - val_loss: 1.1071 - val_categorical_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 556us/step - loss: 1.0247 - categorical_accuracy: 0.4333 - val_loss: 1.0486 - val_categorical_accuracy: 0.3667\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 557us/step - loss: 0.9736 - categorical_accuracy: 0.4333 - val_loss: 0.9862 - val_categorical_accuracy: 0.4333\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 622us/step - loss: 0.9263 - categorical_accuracy: 0.4556 - val_loss: 0.9277 - val_categorical_accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 633us/step - loss: 0.8827 - categorical_accuracy: 0.5000 - val_loss: 0.8730 - val_categorical_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 643us/step - loss: 0.8428 - categorical_accuracy: 0.5556 - val_loss: 0.8259 - val_categorical_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 609us/step - loss: 0.8035 - categorical_accuracy: 0.6111 - val_loss: 0.7768 - val_categorical_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 565us/step - loss: 0.7676 - categorical_accuracy: 0.6667 - val_loss: 0.7338 - val_categorical_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 587us/step - loss: 0.7343 - categorical_accuracy: 0.6889 - val_loss: 0.6942 - val_categorical_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 884us/step - loss: 0.7025 - categorical_accuracy: 0.6889 - val_loss: 0.6545 - val_categorical_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 648us/step - loss: 0.6727 - categorical_accuracy: 0.7222 - val_loss: 0.6213 - val_categorical_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 626us/step - loss: 0.6454 - categorical_accuracy: 0.7444 - val_loss: 0.5898 - val_categorical_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 613us/step - loss: 0.6188 - categorical_accuracy: 0.7778 - val_loss: 0.5592 - val_categorical_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 575us/step - loss: 0.5946 - categorical_accuracy: 0.8000 - val_loss: 0.5344 - val_categorical_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 561us/step - loss: 0.5726 - categorical_accuracy: 0.8000 - val_loss: 0.5107 - val_categorical_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 575us/step - loss: 0.5525 - categorical_accuracy: 0.8111 - val_loss: 0.4901 - val_categorical_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 494us/step - loss: 0.5348 - categorical_accuracy: 0.8333 - val_loss: 0.4718 - val_categorical_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 534us/step - loss: 0.5181 - categorical_accuracy: 0.8222 - val_loss: 0.4550 - val_categorical_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 584us/step - loss: 0.5024 - categorical_accuracy: 0.8222 - val_loss: 0.4393 - val_categorical_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 578us/step - loss: 0.4879 - categorical_accuracy: 0.8222 - val_loss: 0.4248 - val_categorical_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 517us/step - loss: 0.4736 - categorical_accuracy: 0.8444 - val_loss: 0.4107 - val_categorical_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 689us/step - loss: 0.4598 - categorical_accuracy: 0.8444 - val_loss: 0.3960 - val_categorical_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 531us/step - loss: 0.4471 - categorical_accuracy: 0.8444 - val_loss: 0.3832 - val_categorical_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 489us/step - loss: 0.4352 - categorical_accuracy: 0.8667 - val_loss: 0.3709 - val_categorical_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 527us/step - loss: 0.4236 - categorical_accuracy: 0.8667 - val_loss: 0.3589 - val_categorical_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 516us/step - loss: 0.4126 - categorical_accuracy: 0.8667 - val_loss: 0.3478 - val_categorical_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 604us/step - loss: 0.4021 - categorical_accuracy: 0.8667 - val_loss: 0.3375 - val_categorical_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 587us/step - loss: 0.3924 - categorical_accuracy: 0.8667 - val_loss: 0.3278 - val_categorical_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 509us/step - loss: 0.3828 - categorical_accuracy: 0.8667 - val_loss: 0.3184 - val_categorical_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 636us/step - loss: 0.3742 - categorical_accuracy: 0.8667 - val_loss: 0.3104 - val_categorical_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 773us/step - loss: 0.3660 - categorical_accuracy: 0.8667 - val_loss: 0.3030 - val_categorical_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 918us/step - loss: 0.3583 - categorical_accuracy: 0.8667 - val_loss: 0.2957 - val_categorical_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 792us/step - loss: 0.3506 - categorical_accuracy: 0.8667 - val_loss: 0.2885 - val_categorical_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 508us/step - loss: 0.3432 - categorical_accuracy: 0.8667 - val_loss: 0.2824 - val_categorical_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 474us/step - loss: 0.3361 - categorical_accuracy: 0.8667 - val_loss: 0.2768 - val_categorical_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 628us/step - loss: 0.3290 - categorical_accuracy: 0.8667 - val_loss: 0.2717 - val_categorical_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 532us/step - loss: 0.3244 - categorical_accuracy: 0.8667 - val_loss: 0.2668 - val_categorical_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 567us/step - loss: 0.3178 - categorical_accuracy: 0.8667 - val_loss: 0.2624 - val_categorical_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 530us/step - loss: 0.3127 - categorical_accuracy: 0.8667 - val_loss: 0.2577 - val_categorical_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 618us/step - loss: 0.3068 - categorical_accuracy: 0.8667 - val_loss: 0.2530 - val_categorical_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 592us/step - loss: 0.3011 - categorical_accuracy: 0.8778 - val_loss: 0.2483 - val_categorical_accuracy: 0.8667\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 639us/step - loss: 0.2954 - categorical_accuracy: 0.8889 - val_loss: 0.2438 - val_categorical_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 572us/step - loss: 0.2903 - categorical_accuracy: 0.8889 - val_loss: 0.2395 - val_categorical_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 485us/step - loss: 0.2849 - categorical_accuracy: 0.8889 - val_loss: 0.2360 - val_categorical_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 541us/step - loss: 0.2801 - categorical_accuracy: 0.8889 - val_loss: 0.2322 - val_categorical_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 534us/step - loss: 0.2746 - categorical_accuracy: 0.8889 - val_loss: 0.2278 - val_categorical_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 635us/step - loss: 0.2691 - categorical_accuracy: 0.8889 - val_loss: 0.2239 - val_categorical_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 643us/step - loss: 0.2649 - categorical_accuracy: 0.8889 - val_loss: 0.2205 - val_categorical_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 601us/step - loss: 0.2601 - categorical_accuracy: 0.8889 - val_loss: 0.2173 - val_categorical_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 587us/step - loss: 0.2563 - categorical_accuracy: 0.8889 - val_loss: 0.2144 - val_categorical_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 575us/step - loss: 0.2519 - categorical_accuracy: 0.8889 - val_loss: 0.2118 - val_categorical_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 810us/step - loss: 0.2486 - categorical_accuracy: 0.8889 - val_loss: 0.2091 - val_categorical_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 599us/step - loss: 0.2442 - categorical_accuracy: 0.8889 - val_loss: 0.2062 - val_categorical_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 555us/step - loss: 0.2399 - categorical_accuracy: 0.8889 - val_loss: 0.2036 - val_categorical_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 498us/step - loss: 0.2358 - categorical_accuracy: 0.9000 - val_loss: 0.2009 - val_categorical_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 531us/step - loss: 0.2311 - categorical_accuracy: 0.9111 - val_loss: 0.1980 - val_categorical_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 484us/step - loss: 0.2268 - categorical_accuracy: 0.9111 - val_loss: 0.1953 - val_categorical_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 540us/step - loss: 0.2224 - categorical_accuracy: 0.9111 - val_loss: 0.1927 - val_categorical_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 668us/step - loss: 0.2188 - categorical_accuracy: 0.9111 - val_loss: 0.1905 - val_categorical_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 477us/step - loss: 0.2147 - categorical_accuracy: 0.9111 - val_loss: 0.1877 - val_categorical_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 505us/step - loss: 0.2106 - categorical_accuracy: 0.9222 - val_loss: 0.1857 - val_categorical_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 516us/step - loss: 0.2069 - categorical_accuracy: 0.9222 - val_loss: 0.1825 - val_categorical_accuracy: 0.9333\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 628us/step - loss: 0.2028 - categorical_accuracy: 0.9222 - val_loss: 0.1796 - val_categorical_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 584us/step - loss: 0.1988 - categorical_accuracy: 0.9222 - val_loss: 0.1766 - val_categorical_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 586us/step - loss: 0.1951 - categorical_accuracy: 0.9222 - val_loss: 0.1739 - val_categorical_accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 540us/step - loss: 0.1913 - categorical_accuracy: 0.9222 - val_loss: 0.1713 - val_categorical_accuracy: 0.9333\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 556us/step - loss: 0.1885 - categorical_accuracy: 0.9222 - val_loss: 0.1690 - val_categorical_accuracy: 0.9333\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 540us/step - loss: 0.1844 - categorical_accuracy: 0.9222 - val_loss: 0.1668 - val_categorical_accuracy: 0.9333\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 589us/step - loss: 0.1816 - categorical_accuracy: 0.9222 - val_loss: 0.1643 - val_categorical_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 506us/step - loss: 0.1787 - categorical_accuracy: 0.9222 - val_loss: 0.1622 - val_categorical_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 601us/step - loss: 0.1750 - categorical_accuracy: 0.9444 - val_loss: 0.1606 - val_categorical_accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 594us/step - loss: 0.1724 - categorical_accuracy: 0.9444 - val_loss: 0.1583 - val_categorical_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 548us/step - loss: 0.1687 - categorical_accuracy: 0.9444 - val_loss: 0.1561 - val_categorical_accuracy: 0.9333\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 896us/step - loss: 0.1652 - categorical_accuracy: 0.9556 - val_loss: 0.1539 - val_categorical_accuracy: 0.9333\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 702us/step - loss: 0.1624 - categorical_accuracy: 0.9556 - val_loss: 0.1521 - val_categorical_accuracy: 0.9333\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 769us/step - loss: 0.1583 - categorical_accuracy: 0.9556 - val_loss: 0.1505 - val_categorical_accuracy: 0.9333\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 579us/step - loss: 0.1553 - categorical_accuracy: 0.9556 - val_loss: 0.1482 - val_categorical_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 770us/step - loss: 0.1521 - categorical_accuracy: 0.9778 - val_loss: 0.1460 - val_categorical_accuracy: 0.9333\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 710us/step - loss: 0.1495 - categorical_accuracy: 0.9778 - val_loss: 0.1450 - val_categorical_accuracy: 0.9333\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 769us/step - loss: 0.1464 - categorical_accuracy: 0.9667 - val_loss: 0.1435 - val_categorical_accuracy: 0.9333\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 588us/step - loss: 0.1437 - categorical_accuracy: 0.9667 - val_loss: 0.1416 - val_categorical_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 647us/step - loss: 0.1411 - categorical_accuracy: 0.9667 - val_loss: 0.1405 - val_categorical_accuracy: 0.9333\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 626us/step - loss: 0.1383 - categorical_accuracy: 0.9667 - val_loss: 0.1389 - val_categorical_accuracy: 0.9333\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 669us/step - loss: 0.1351 - categorical_accuracy: 0.9778 - val_loss: 0.1360 - val_categorical_accuracy: 0.9333\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 661us/step - loss: 0.1329 - categorical_accuracy: 0.9667 - val_loss: 0.1344 - val_categorical_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.1303 - categorical_accuracy: 0.9667 - val_loss: 0.1328 - val_categorical_accuracy: 0.9333\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 644us/step - loss: 0.1270 - categorical_accuracy: 0.9667 - val_loss: 0.1310 - val_categorical_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 616us/step - loss: 0.1241 - categorical_accuracy: 0.9778 - val_loss: 0.1291 - val_categorical_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 680us/step - loss: 0.1218 - categorical_accuracy: 0.9667 - val_loss: 0.1276 - val_categorical_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 714us/step - loss: 0.1189 - categorical_accuracy: 0.9778 - val_loss: 0.1265 - val_categorical_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 609us/step - loss: 0.1164 - categorical_accuracy: 0.9778 - val_loss: 0.1248 - val_categorical_accuracy: 0.9333\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 563us/step - loss: 0.1143 - categorical_accuracy: 0.9667 - val_loss: 0.1240 - val_categorical_accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 504us/step - loss: 0.1116 - categorical_accuracy: 0.9667 - val_loss: 0.1234 - val_categorical_accuracy: 0.9333\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 532us/step - loss: 0.1091 - categorical_accuracy: 0.9667 - val_loss: 0.1231 - val_categorical_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import layers, optimizers, losses, metrics\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "# load dataset\n",
    "dataframe = pd.read_csv(\"iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "\n",
    "\n",
    "# shuffle data to shuffle rocks & mine data\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "x = dataset[:,0:4].astype(float)\n",
    "y = dataset[:,4]\n",
    "\n",
    "\n",
    "#normaliazing data\n",
    "x -= x.mean(axis=0)\n",
    "x /= x.std(axis=0)\n",
    "\n",
    "\n",
    "#encode label in 1 and 0 and 2\n",
    "a = y.tolist()\n",
    "b= []\n",
    "for i in a:\n",
    "    if i == 'Iris-setosa':\n",
    "        i = 1\n",
    "        b.append(i)\n",
    "    elif i == 'Iris-versicolor':\n",
    "        i = 2\n",
    "        b.append(i)\n",
    "    else:\n",
    "        i = 0\n",
    "        b.append(i)\n",
    "y = np.asarray(b)\n",
    "\n",
    "\n",
    "#split data in test and train\n",
    "x_test = x[:30]\n",
    "x_train = x[30:]\n",
    "y_test = y[:30]\n",
    "y_train = y[30:]\n",
    "\n",
    "\n",
    "# split validation data\n",
    "x_val = x_train[:30]\n",
    "partial_x_train = x_train[30:]\n",
    "y_val = y_train[:30]\n",
    "partial_y_train = y_train[30:]\n",
    "\n",
    "\n",
    "#one hot encoding test, train and validation labels\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "partial_y_train = to_categorical(partial_y_train)\n",
    "\n",
    "\n",
    "#model subclassing\n",
    "class myModel(keras.Model):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super(myModel, self).__init__()\n",
    "        self.dense1 = Dense(8, activation='relu')\n",
    "        self.dense2 = Dense(3, activation = 'softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = myModel()\n",
    "sgd = optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "loss = losses.categorical_crossentropy\n",
    "metrics = [metrics.categorical_accuracy]\n",
    "\n",
    "\n",
    "#compiler\n",
    "model.compile(sgd,loss,metrics)\n",
    "\n",
    "\n",
    "#train model\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=100,batch_size=5,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 397us/step\n",
      "[0.08571628481149673, 0.9333333373069763]\n"
     ]
    }
   ],
   "source": [
    "#evaluate on test data\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
